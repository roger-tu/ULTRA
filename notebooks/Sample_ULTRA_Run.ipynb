{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8ddcab",
   "metadata": {},
   "source": [
    "# Sample notebook for running ULTRA\n",
    "This notebook serves as a sample notebook to create a dataset, run the dataset, and evaluate/explore the output predictions with the ULTRA foundation model. The notebook is divided into three sections: dataset creation, running the model, and prediction evaluation.\n",
    "\n",
    "prior to running code, you want to setup your file directory. I recommend creating a project folder that you can download data, organize your notebook and code. Sample structure like this:\n",
    "* kg-models/\n",
    "    * code/\n",
    "    * data/\n",
    "    * notebooks/\n",
    "    * output/\n",
    "\n",
    "You can download [ULTRA](https://github.com/roger-tu/ULTRA) under `code/ULTRA` (as well as any other algorithms you want to try), and this notebook under `notebooks/ultra_nb/999_Sample_ULTRA_Run.ipynb`.\n",
    "\n",
    "Alternatively, clone this repo and run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34617bf-006d-4423-9e76-c11d88ac1f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:17.485551Z",
     "iopub.status.busy": "2025-08-13T18:09:17.485103Z",
     "iopub.status.idle": "2025-08-13T18:09:29.115336Z",
     "shell.execute_reply": "2025-08-13T18:09:29.114839Z",
     "shell.execute_reply.started": "2025-08-13T18:09:17.485534Z"
    }
   },
   "outputs": [],
   "source": [
    "# pathing\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import pathlib as Path\n",
    "\n",
    "# data sci & stats\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# run model\n",
    "import shutil\n",
    "import subprocess\n",
    "import torch\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# get model dicts\n",
    "sys.path.append('../')\n",
    "from ultra import datasets, data_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eed057",
   "metadata": {},
   "source": [
    "# Add your dataset to `ultra.datasets`\n",
    "* before beginning add your example dataset into ultra.datasets as a class object in ultra/datasets\n",
    "* you can copy and paste the code below for this particular notebook\n",
    "* this tells the model that you can find the dataset at a particular location, and how the dataset is formatted.\n",
    "\n",
    "```python\n",
    "# After the TransductiveDatset Class, approx Line 379\n",
    "class SamplePrimeKG(TransductiveDataset):\n",
    "    '''\n",
    "    This is a sample PrimeKG dataset to preprocess for ULTRA usage. \n",
    "    Its just PrimeKG randomly split using seed 42.\n",
    "    Two variables need to be specified: name and delimiter\n",
    "    '''\n",
    "    name = 'primekg' # the file name holding the train/test/valid dataset\n",
    "    delimiter = '\\t' # format of the files in the folder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb77e12",
   "metadata": {},
   "source": [
    "# Dataset Download, Creation and Preprocessing\n",
    "\n",
    "This is an example of creating a custom dataset to run in ULTRA. Here I create a modified PrimeKG and insert it into the codebase. This step is required because the model needs to do its own pre-processing on the raw triples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b96fc8",
   "metadata": {},
   "source": [
    "## Download and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbb765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-02 19:28:54--  https://dataverse.harvard.edu/api/access/datafile/6180620\n",
      "Resolving dataverse.harvard.edu (dataverse.harvard.edu)... 3.90.211.193, 18.214.210.234, 52.6.5.183\n",
      "Connecting to dataverse.harvard.edu (dataverse.harvard.edu)|3.90.211.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://dvn-cloud.s3.amazonaws.com/10.7910/DVN/IXA7BM/1805e679c4c-72137dbedbf1?response-content-disposition=attachment%3B%20filename%2A%3DUTF-8%27%27kg.csv&response-content-type=text%2Fcsv&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250902T192855Z&X-Amz-SignedHeaders=host&X-Amz-Credential=AKIAIEJ3NV7UYCSRJC7A%2F20250902%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Expires=3600&X-Amz-Signature=97b8cfae36308479fe4338ef17b306f80fcb73211beb25967ae5eea7e78ef5df [following]\n",
      "--2025-09-02 19:28:55--  https://dvn-cloud.s3.amazonaws.com/10.7910/DVN/IXA7BM/1805e679c4c-72137dbedbf1?response-content-disposition=attachment%3B%20filename%2A%3DUTF-8%27%27kg.csv&response-content-type=text%2Fcsv&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250902T192855Z&X-Amz-SignedHeaders=host&X-Amz-Credential=AKIAIEJ3NV7UYCSRJC7A%2F20250902%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Expires=3600&X-Amz-Signature=97b8cfae36308479fe4338ef17b306f80fcb73211beb25967ae5eea7e78ef5df\n",
      "Resolving dvn-cloud.s3.amazonaws.com (dvn-cloud.s3.amazonaws.com)... 16.15.186.17, 52.216.211.17, 16.15.184.63, ...\n",
      "Connecting to dvn-cloud.s3.amazonaws.com (dvn-cloud.s3.amazonaws.com)|16.15.186.17|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 981751236 (936M) [text/csv]\n",
      "Saving to: ‘../data/primekg.csv’\n",
      "\n",
      "../data/primekg.csv 100%[===================>] 936.27M  28.1MB/s    in 37s     \n",
      "\n",
      "2025-09-02 19:29:32 (25.0 MB/s) - ‘../data/primekg.csv’ saved [981751236/981751236]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "!wget -O ../data/primekg.csv https://dataverse.harvard.edu/api/access/datafile/6180620 --no-check-certificate -nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c32c5f",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ccf89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>display_relation</th>\n",
       "      <th>x_index</th>\n",
       "      <th>x_id</th>\n",
       "      <th>x_type</th>\n",
       "      <th>x_name</th>\n",
       "      <th>x_source</th>\n",
       "      <th>y_index</th>\n",
       "      <th>y_id</th>\n",
       "      <th>y_type</th>\n",
       "      <th>y_name</th>\n",
       "      <th>y_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>protein_protein</td>\n",
       "      <td>ppi</td>\n",
       "      <td>0</td>\n",
       "      <td>9796</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>PHYHIP</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>8889</td>\n",
       "      <td>56992</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>KIF15</td>\n",
       "      <td>NCBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>protein_protein</td>\n",
       "      <td>ppi</td>\n",
       "      <td>1</td>\n",
       "      <td>7918</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>GPANK1</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>2798</td>\n",
       "      <td>9240</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>PNMA1</td>\n",
       "      <td>NCBI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          relation display_relation  x_index  x_id        x_type  x_name  \\\n",
       "0  protein_protein              ppi        0  9796  gene/protein  PHYHIP   \n",
       "1  protein_protein              ppi        1  7918  gene/protein  GPANK1   \n",
       "\n",
       "  x_source  y_index   y_id        y_type y_name y_source  \n",
       "0     NCBI     8889  56992  gene/protein  KIF15     NCBI  \n",
       "1     NCBI     2798   9240  gene/protein  PNMA1     NCBI  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into pandas\n",
    "df = pd.read_csv('../data/primekg.csv',low_memory=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3bd3f",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596f7942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>source_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHYHIP</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>9796</td>\n",
       "      <td>NCBI:9796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPANK1</td>\n",
       "      <td>gene/protein</td>\n",
       "      <td>NCBI</td>\n",
       "      <td>7918</td>\n",
       "      <td>NCBI:7918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name          type source    id source_label\n",
       "0  PHYHIP  gene/protein   NCBI  9796    NCBI:9796\n",
       "1  GPANK1  gene/protein   NCBI  7918    NCBI:7918"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the node heads/tails and get unique nodes\n",
    "node_heads = df[['x_index','x_id','x_name','x_type','x_source']].rename(columns = {'x_index':'index','x_id':'id','x_name':'name','x_type':'type','x_source':'source'})\n",
    "node_tails = df[['y_index','y_id','y_name','y_type','y_source']].rename(columns = {'y_index':'index','y_id':'id','y_name':'name','y_type':'type','y_source':'source'})\n",
    "\n",
    "# remove duplicates\n",
    "nodes = pd.concat([node_heads,node_tails])[['name','type','source','id']].drop_duplicates()\n",
    "nodes['source_label'] = nodes['source'] +':'+nodes['id']\n",
    "\n",
    "# export to data folder\n",
    "nodes[['name','type','source','id','source_label']].rename(columns = {'id':'source_id'}).to_csv('../data/nodes.txt',sep = '\\t', header = True, index = False)\n",
    "nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c070a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create node to label mapping and map the triples\n",
    "nodes_dict = dict(zip(nodes['name'],nodes['source_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2247066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>head_label</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHYHIP</td>\n",
       "      <td>ppi</td>\n",
       "      <td>KIF15</td>\n",
       "      <td>NCBI:9796</td>\n",
       "      <td>NCBI:56992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPANK1</td>\n",
       "      <td>ppi</td>\n",
       "      <td>PNMA1</td>\n",
       "      <td>NCBI:7918</td>\n",
       "      <td>NCBI:9240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     head relation   tail head_label  tail_label\n",
       "0  PHYHIP      ppi  KIF15  NCBI:9796  NCBI:56992\n",
       "1  GPANK1      ppi  PNMA1  NCBI:7918   NCBI:9240"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples = df[['x_name','display_relation','y_name']].drop_duplicates().rename(columns = {'x_name':'head','display_relation':'relation','y_name':'tail'})\n",
    "triples['head_label'] = triples['head'].apply(lambda x: nodes_dict[x])\n",
    "triples['tail_label'] = triples['tail'].apply(lambda x: nodes_dict[x])\n",
    "\n",
    "# export the data\n",
    "triples[['head_label','relation','tail_label']].to_csv('../data/graph.txt',sep = '\\t', header = False, index = False)\n",
    "triples.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48493e-060b-4a8f-ab25-0157948c12a7",
   "metadata": {},
   "source": [
    "## Load Preprocessed data\n",
    "PrimeKG is a semantic knowledge graph. The raw form is just 1 file containing nodes/edges information. I separated them into two different files: nodes and graph.\n",
    "* The nodes file is located here: `../../data/nodes.txt`\n",
    "* All edges (graph) is located here: `../../data/graph.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b3b4b9-9d09-446e-bee4-6cb8f1a1909f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:29.116379Z",
     "iopub.status.busy": "2025-08-13T18:09:29.116086Z",
     "iopub.status.idle": "2025-08-13T18:09:31.064713Z",
     "shell.execute_reply": "2025-08-13T18:09:31.064210Z",
     "shell.execute_reply.started": "2025-08-13T18:09:29.116362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes shape: (129375, 5)\n",
      "Graph shape: (8100048, 3)\n"
     ]
    }
   ],
   "source": [
    "# using polars to import in the dataframes\n",
    "nodes = pl.read_csv(\n",
    "    '../data/nodes.txt',\n",
    "    separator='\\t',\n",
    "    schema={\n",
    "        'name':pl.String,\n",
    "        'type':pl.String,\n",
    "        'source':pl.String,\n",
    "        'source_id':pl.String,\n",
    "        'source_label':pl.String\n",
    "    }\n",
    ")\n",
    "\n",
    "graph = pl.read_csv('../data/graph.txt', separator='\\t', new_columns=['h','r','t'])\n",
    "# get shapes\n",
    "print(f'Nodes shape: {nodes.shape}')\n",
    "print(f'Graph shape: {graph.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0735045e",
   "metadata": {},
   "source": [
    "## Create data splits\n",
    "* we're just going to randomly split the data into 80/10/10% train, test, valid splits here\n",
    "* in ULTRA, the model needs a training set to calculate relative relational and relative entity embeddings\n",
    "* it's a foundation model in the sense that you can apply the model on any dataset, but the model will still need to compute relative embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12c5ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:31.065589Z",
     "iopub.status.busy": "2025-08-13T18:09:31.065239Z",
     "iopub.status.idle": "2025-08-13T18:09:33.049888Z",
     "shell.execute_reply": "2025-08-13T18:09:33.049042Z",
     "shell.execute_reply.started": "2025-08-13T18:09:31.065574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6480038, 3)\n",
      "Test shape: (810005, 3)\n",
      "Valid shape: (810005, 3)\n"
     ]
    }
   ],
   "source": [
    "train = graph.sample(fraction=0.8, seed=42)\n",
    "test = graph.join(train, on = ['h','r','t'], how = 'anti').sample(fraction=0.5, seed=42)\n",
    "valid = graph.join(pl.concat([train, test]), on = ['h','r','t'], how = 'anti')\n",
    "\n",
    "print(f'Train shape: {train.shape}')\n",
    "print(f'Test shape: {test.shape}')\n",
    "print(f'Valid shape: {valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875751f-5bd9-476e-ae57-76a982f73346",
   "metadata": {},
   "source": [
    "## export the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b8c7a7-70bd-423c-a955-a5601a68b93b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:33.051135Z",
     "iopub.status.busy": "2025-08-13T18:09:33.050831Z",
     "iopub.status.idle": "2025-08-13T18:09:33.054761Z",
     "shell.execute_reply": "2025-08-13T18:09:33.054077Z",
     "shell.execute_reply.started": "2025-08-13T18:09:33.051119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n",
      "File already exists: ../data/primekg/raw/train.txt\n",
      "File already exists: ../data/primekg/raw/test.txt\n",
      "File already exists: ../data/primekg/raw/valid.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/primekg/raw'\n",
    "\n",
    "# check if directory exists, if not create it\n",
    "if osp.exists(data_dir)==False:\n",
    "    print(f'Creating directory: {data_dir}')\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "else:\n",
    "    print(f'Directory already exists')\n",
    "\n",
    "\n",
    "# export files\n",
    "for i in ['train', 'test','valid']:\n",
    "    if osp.exists(export_dir := osp.join(data_dir,f'{i}.txt'))==False:\n",
    "        print(f'Creating file: {export_dir}')\n",
    "        tmp_df = eval(i)\n",
    "        tmp_df.write_csv(export_dir, separator='\\t', include_header=False)\n",
    "    else:\n",
    "        print(f'File already exists: {export_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c529cd",
   "metadata": {},
   "source": [
    "## build dataset object\n",
    "\n",
    "After exporting the train/test/valid object, go to `ultra.datasets` and add your own class object. If you didn't do this before beginning you may need to restart the jupyter notebook or reimport the `datasets` library into the notebook. The class object example looks like this. We need this inorder to preprocess and build the dataset to be used by ULTRA.\n",
    "\n",
    "\n",
    "```python\n",
    "class SamplePrimeKG(TransductiveDataset):\n",
    "    '''\n",
    "    This is a sample PrimeKG dataset to preprocess for ULTRA usage. \n",
    "    Its just PrimeKG randomly split using seed 42.\n",
    "    Two variables need to be specified: name and delimiter\n",
    "    '''\n",
    "    name = 'sample_primekg' # the file name holding the train/test/valid dataset\n",
    "    delimiter = '\\t' # format of the files in the folder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f3388",
   "metadata": {},
   "source": [
    "### build dataset object by calling the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b31a8acd-061d-48c9-9558-1b778b62c3df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:33.055216Z",
     "iopub.status.busy": "2025-08-13T18:09:33.055086Z",
     "iopub.status.idle": "2025-08-13T18:09:40.687615Z",
     "shell.execute_reply": "2025-08-13T18:09:40.686850Z",
     "shell.execute_reply.started": "2025-08-13T18:09:33.055204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/notebooks/../ultra/tasks.py:199: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1744376164423/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  Ahh = torch.sparse.mm(EhT, Eh).coalesce()\n",
      "Done!\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/notebooks/../ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    }
   ],
   "source": [
    "# just calling the class object will create the dataset\n",
    "# need to point the class to the root directory of the dataset\n",
    "sample_data = datasets.SamplePrimeKG(root='../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e997875a-6367-44c6-ac99-23d116b4d257",
   "metadata": {},
   "source": [
    "#### extract the entity to id dictionary conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f27228af-4700-4857-bea7-16fee25d0849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:40.688578Z",
     "iopub.status.busy": "2025-08-13T18:09:40.688366Z",
     "iopub.status.idle": "2025-08-13T18:09:40.691639Z",
     "shell.execute_reply": "2025-08-13T18:09:40.691181Z",
     "shell.execute_reply.started": "2025-08-13T18:09:40.688564Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_id2ent_rel_dict(dataset)->dict:\n",
    "    return {v:k for k,v in dataset.entity_vocab.items()}, {v:k for k,v in dataset.relation_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c4a79b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:40.692224Z",
     "iopub.status.busy": "2025-08-13T18:09:40.692091Z",
     "iopub.status.idle": "2025-08-13T18:09:50.957407Z",
     "shell.execute_reply": "2025-08-13T18:09:50.956496Z",
     "shell.execute_reply.started": "2025-08-13T18:09:40.692212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: ../output/Ultra/SamplePrimeKG\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../output/Ultra/SamplePrimeKG'\n",
    "# extract dictionaries\n",
    "tmp = get_id2ent_rel_dict(sample_data)\n",
    "\n",
    "# check if directory exists, if not create it\n",
    "if osp.exists(output_dir)==False:\n",
    "    print(f'Creating directory: {output_dir}')\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "    # dump id2ent\n",
    "    with open(osp.join(output_dir, 'id2ent_dict.pkl'),'wb') as f:\n",
    "        pickle.dump(tmp[0],f)\n",
    "\n",
    "    # dump id2rel\n",
    "    with open(osp.join(output_dir, 'id2rel_dict.pkl'),'wb') as f:\n",
    "        pickle.dump(tmp[1],f)\n",
    "\n",
    "else:\n",
    "    print(f'Directory already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d7a9f",
   "metadata": {},
   "source": [
    "#### create entity to id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "876c2867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:50.958736Z",
     "iopub.status.busy": "2025-08-13T18:09:50.958261Z",
     "iopub.status.idle": "2025-08-13T18:09:50.962407Z",
     "shell.execute_reply": "2025-08-13T18:09:50.961701Z",
     "shell.execute_reply.started": "2025-08-13T18:09:50.958721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent2name_dict.pkl not found, creating\n"
     ]
    }
   ],
   "source": [
    "# also make sure ent2name_dict.pkl exists. we can pull from an existing directory\n",
    "if osp.exists(osp.join(output_dir, \"ent2name_dict.pkl\")) == False:\n",
    "    print(\"ent2name_dict.pkl not found, creating\")\n",
    "    ent2name_dict = dict(zip(nodes['source_label'].to_list(),nodes['name'].to_list()))\n",
    "    \n",
    "    with open('../data/ent2name_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(ent2name_dict, f)\n",
    "else:\n",
    "    print(\"ent2name_dict.pkl already exists, skipping copy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8834ab9-d06b-469d-8c52-a698bc087fa8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Run Model\n",
    "* You can run the model and evaluate/get predictions across the test/valid set \n",
    "* You can also run an inference script that evaluates 1 node at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff972",
   "metadata": {},
   "source": [
    "## Run evaluation on test/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354fd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 00:51:42.821000 11913 site-packages/torch/distributed/run.py:793] \n",
      "W0813 00:51:42.821000 11913 site-packages/torch/distributed/run.py:793] *****************************************\n",
      "W0813 00:51:42.821000 11913 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0813 00:51:42.821000 11913 site-packages/torch/distributed/run.py:793] *****************************************\n",
      "[rank3]:[W813 00:51:45.815917586 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank2]:[W813 00:51:45.049605982 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank0]:[W813 00:51:45.071238775 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank1]:[W813 00:51:45.085480406 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "00:51:46   Random seed: 1024\n",
      "00:51:46   Config file: /home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/config/transductive/inference_pkg.yaml\n",
      "00:51:46   {'checkpoint': '/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ckpts/ultra_primekg_50g_ft_epoch_1.pth',\n",
      " 'dataset': {'class': 'SamplePrimeKG',\n",
      "             'root': '~/knowledge-graph-workflows-and-models-team-primeKG/data'},\n",
      " 'model': {'class': 'Ultra',\n",
      "           'entity_model': {'aggregate_func': 'sum',\n",
      "                            'class': 'EntityNBFNet',\n",
      "                            'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
      "                            'input_dim': 64,\n",
      "                            'layer_norm': True,\n",
      "                            'message_func': 'distmult',\n",
      "                            'short_cut': True},\n",
      "           'relation_model': {'aggregate_func': 'sum',\n",
      "                              'class': 'RelNBFNet',\n",
      "                              'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
      "                              'input_dim': 64,\n",
      "                              'layer_norm': True,\n",
      "                              'message_func': 'distmult',\n",
      "                              'short_cut': True}},\n",
      " 'optimizer': {'class': 'AdamW', 'lr': 0.0005},\n",
      " 'output_dir': '~/knowledge-graph-workflows-and-models-team-primeKG/output/',\n",
      " 'task': {'adversarial_temperature': 1,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10'],\n",
      "          'name': 'TransductiveInference',\n",
      "          'num_negative': 256,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_per_epoch': 4,\n",
      "           'batch_size': 48,\n",
      "           'gpus': [0, 1, 2, 3],\n",
      "           'log_interval': 100,\n",
      "           'num_epoch': 0,\n",
      "           'tensorboard': None}}\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "00:51:46   SamplePrimeKG dataset\n",
      "00:51:46   #train: 6480038, #valid: 810005, #test: 810005\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/run.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(cfg.checkpoint, map_location=\"cpu\")\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/run.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(cfg.checkpoint, map_location=\"cpu\")\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/run.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(cfg.checkpoint, map_location=\"cpu\")\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/run.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(cfg.checkpoint, map_location=\"cpu\")\n",
      "00:51:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "00:51:47   Evaluate on valid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n",
      "Load rspmm extension. This may take a while...\n",
      "Load rspmm extension. This may take a while...\n",
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:43:28   mr: 168.763\n",
      "06:43:28   mrr: 0.850323\n",
      "06:43:28   hits@1: 0.810478\n",
      "06:43:28   hits@3: 0.880861\n",
      "06:43:28   hits@10: 0.916597\n",
      "06:43:28   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "06:43:28   Evaluate on test\n"
     ]
    }
   ],
   "source": [
    "# Set pixi as environment variable so subprocess knows where to find it\n",
    "# V100 platform use '7.0+PTX'\n",
    "os.environ['TORCH_CUDA_ARCH_LIST'] = '8.9+PTX' # L4/L40s\n",
    "my_env = os.environ.copy()\n",
    "my_env[\"PATH\"] = f\"/home/sagemaker-user/.pixi/bin:{my_env['PATH']}\"\n",
    "\n",
    "# subprocess command\n",
    "cmd = f'pixi run -e gpu torchrun --nproc-per-node=4 \\\n",
    "    \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/run.py\" \\\n",
    "    -c \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/config/transductive/inference_pkg.yaml\" \\\n",
    "    --ckpt \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ckpts/ultra_primekg_50g_ft_epoch_1.pth\" \\\n",
    "    --dataset \"SamplePrimeKG\" \\\n",
    "    --gpus [0,1,2,3] \\\n",
    "    --epochs 0 \\\n",
    "    --bpe 4 \\\n",
    "    --tb null'\n",
    "\n",
    "# execute subprocess\n",
    "subprocess.run(cmd,env=my_env, shell=True)\n",
    "\n",
    "# you'll get like 1000 parquet files that need to be combined\n",
    "# export is setup this way because GPU can't keep everything in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd7d28",
   "metadata": {},
   "source": [
    "## Run inference for a particular query\n",
    "* Notice a different command and `-c` that is run. Here it's `inference.py` with the `-c` flag as `inference_single.yaml`\n",
    "* Full paths must be specified for each flag, not relative directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d78703e8-c869-4a77-a78d-bd6e620b5f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T02:40:50.771242Z",
     "iopub.status.busy": "2025-06-19T02:40:50.770393Z",
     "iopub.status.idle": "2025-06-19T02:43:07.555304Z",
     "shell.execute_reply": "2025-06-19T02:43:07.554589Z",
     "shell.execute_reply.started": "2025-06-19T02:40:50.771198Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 17:35:40.066000 30367 site-packages/torch/distributed/run.py:793] \n",
      "W0813 17:35:40.066000 30367 site-packages/torch/distributed/run.py:793] *****************************************\n",
      "W0813 17:35:40.066000 30367 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0813 17:35:40.066000 30367 site-packages/torch/distributed/run.py:793] *****************************************\n",
      "[rank1]:[W813 17:35:42.891823336 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank3]:[W813 17:35:42.145715522 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank0]:[W813 17:35:42.228298721 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank2]:[W813 17:35:42.230365988 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "17:35:43   Random seed: 1024\n",
      "17:35:43   Config file: /home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/config/transductive/inference_single.yaml\n",
      "17:35:43   {'checkpoint': '/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ckpts/ultra_primekg_50g_ft_epoch_1.pth',\n",
      " 'dataset': {'class': 'SamplePrimeKG',\n",
      "             'root': '/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/data/'},\n",
      " 'infer': {'h_ent': 'NCBI:7297', 'rel': 'associated with'},\n",
      " 'model': {'class': 'Ultra',\n",
      "           'entity_model': {'aggregate_func': 'sum',\n",
      "                            'class': 'EntityNBFNet',\n",
      "                            'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
      "                            'input_dim': 64,\n",
      "                            'layer_norm': True,\n",
      "                            'message_func': 'distmult',\n",
      "                            'short_cut': True},\n",
      "           'relation_model': {'aggregate_func': 'sum',\n",
      "                              'class': 'RelNBFNet',\n",
      "                              'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
      "                              'input_dim': 64,\n",
      "                              'layer_norm': True,\n",
      "                              'message_func': 'distmult',\n",
      "                              'short_cut': True}},\n",
      " 'optimizer': {'class': 'AdamW', 'lr': 0.0005},\n",
      " 'output_dir': '~/knowledge-graph-workflows-and-models-team-primeKG/output/',\n",
      " 'task': {'adversarial_temperature': 1,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10'],\n",
      "          'name': 'TransductiveInference',\n",
      "          'num_negative': 256,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_per_epoch': None,\n",
      "           'batch_size': 8,\n",
      "           'gpus': [0, 1, 2, 3],\n",
      "           'log_interval': 100,\n",
      "           'num_epoch': 0}}\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/datasets.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "17:35:43   SamplePrimeKG dataset\n",
      "17:35:43   #train: 6480038, #valid: 810005, #test: 810005\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/tasks.py:199: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1744376164423/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  Ahh = torch.sparse.mm(EhT, Eh).coalesce()\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/tasks.py:199: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1744376164423/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  Ahh = torch.sparse.mm(EhT, Eh).coalesce()\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/tasks.py:199: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1744376164423/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  Ahh = torch.sparse.mm(EhT, Eh).coalesce()\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/inference.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(cfg.checkpoint, map_location=\"cpu\")\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ultra/tasks.py:199: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1744376164423/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  Ahh = torch.sparse.mm(EhT, Eh).coalesce()\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/inference.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(cfg.checkpoint, map_location=\"cpu\")\n",
      "17:36:51   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "17:36:51   Run inference on NCBI:7297 - associated with\n",
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/inference.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(cfg.checkpoint, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/inference.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(cfg.checkpoint, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n",
      "Load rspmm extension. This may take a while...\n",
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:36:52   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "17:36:52   Exporting Predictions for batch 0\n",
      "[rank0]:[W813 17:36:55.402408531 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='pixi run -e gpu torchrun --nproc-per-node=4 \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/inference.py\" -c \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/config/transductive/inference_single.yaml\" --ckpt \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ckpts/ultra_primekg_50g_ft_epoch_1.pth\" --data_dir \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/data/\" --dataset \"SamplePrimeKG\" --gpus [0,1,2,3] --h_ent NCBI:7297 --rel \"associated with\"', returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set pixi as environment variable so subprocess knows where to find it\n",
    "os.environ['TORCH_CUDA_ARCH_LIST'] = '8.9+PTX' # L4/L40s\n",
    "my_env = os.environ.copy()\n",
    "my_env[\"PATH\"] = f\"/home/sagemaker-user/.pixi/bin:{my_env['PATH']}\"\n",
    "\n",
    "# variables\n",
    "h = 'NCBI:7297' # TYK2\n",
    "r = 'associated with'\n",
    "\n",
    "# initialize command\n",
    "cmd = f'pixi run -e gpu torchrun --nproc-per-node=4 \\\n",
    "\"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/script/inference.py\" \\\n",
    "-c \\\n",
    "\"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/config/transductive/inference_single.yaml\" \\\n",
    "--ckpt \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/code/ULTRA/ckpts/ultra_primekg_50g_ft_epoch_1.pth\" \\\n",
    "--data_dir \"/home/sagemaker-user/knowledge-graph-workflows-and-models-team-primeKG/data/\" \\\n",
    "--dataset \"SamplePrimeKG\" \\\n",
    "--gpus [0,1,2,3] \\\n",
    "--h_ent {h} --rel \"{r}\"'\n",
    "\n",
    "# execute subprocess\n",
    "subprocess.run(cmd,env=my_env,shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b1d2f-2921-4f2c-ac36-00277cd3c1be",
   "metadata": {},
   "source": [
    "# Process and collate datasets\n",
    "* If you ran the evaluation on test/valid instead of single inference, you probably got thousands of parquet files in your output directory\n",
    "* we need to combine those outputs, and process them into human readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f136c5-64c1-4cc9-8994-49daef1dbda0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:09:50.963729Z",
     "iopub.status.busy": "2025-08-13T18:09:50.963441Z",
     "iopub.status.idle": "2025-08-13T18:09:50.967971Z",
     "shell.execute_reply": "2025-08-13T18:09:50.967482Z",
     "shell.execute_reply.started": "2025-08-13T18:09:50.963715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent directory of both results: ../../output/Ultra/SamplePrimeKG\n",
      "Batched file name: 2025-08-13-00-51-45\n"
     ]
    }
   ],
   "source": [
    "# output directory\n",
    "batched = '../../output/Ultra/SamplePrimeKG/2025-08-13-00-51-45' # test/valid\n",
    "single = '../../output/Ultra/SamplePrimeKG/2025-08-13-17-35-42' # single TYK2-associated_with query\n",
    "\n",
    "print(f'Parent directory of both results: {osp.dirname(batched)}')\n",
    "print(f'Batched file name: {osp.basename(batched)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d67f6c-3463-449e-a2f3-22cb25ba2e0b",
   "metadata": {},
   "source": [
    "## process single query\n",
    "* I keep the scores in the single query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2285c674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>h</th><th>r</th><th>t</th><th>t_filt_rank</th><th>t_unfilt_rank</th><th>t_pred_filt</th><th>t_pred_unfilt</th><th>t_pred_score</th><th>t_mask</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[f64]</td><td>list[bool]</td></tr></thead><tbody><tr><td>6031</td><td>5</td><td>86164</td><td>1</td><td>23</td><td>[7123, 10907, … 86164]</td><td>[31225, 24719, … 6031]</td><td>[-20.370192, -20.601143, … -5.81477]</td><td>[true, true, … true]</td></tr><tr><td>6031</td><td>5</td><td>2045</td><td>1</td><td>24</td><td>[7123, 10907, … 86164]</td><td>[31225, 24719, … 6031]</td><td>[-20.370192, -20.601143, … -5.81477]</td><td>[true, true, … true]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "┌──────┬─────┬───────┬─────────────┬───┬──────────────┬──────────────┬──────────────┬──────────────┐\n",
       "│ h    ┆ r   ┆ t     ┆ t_filt_rank ┆ … ┆ t_pred_filt  ┆ t_pred_unfil ┆ t_pred_score ┆ t_mask       │\n",
       "│ ---  ┆ --- ┆ ---   ┆ ---         ┆   ┆ ---          ┆ t            ┆ ---          ┆ ---          │\n",
       "│ i64  ┆ i64 ┆ i64   ┆ i64         ┆   ┆ list[i64]    ┆ ---          ┆ list[f64]    ┆ list[bool]   │\n",
       "│      ┆     ┆       ┆             ┆   ┆              ┆ list[i64]    ┆              ┆              │\n",
       "╞══════╪═════╪═══════╪═════════════╪═══╪══════════════╪══════════════╪══════════════╪══════════════╡\n",
       "│ 6031 ┆ 5   ┆ 86164 ┆ 1           ┆ … ┆ [7123,       ┆ [31225,      ┆ [-20.370192, ┆ [true, true, │\n",
       "│      ┆     ┆       ┆             ┆   ┆ 10907, …     ┆ 24719, …     ┆ -20.601143,  ┆ … true]      │\n",
       "│      ┆     ┆       ┆             ┆   ┆ 86164]       ┆ 6031]        ┆ … -5.…       ┆              │\n",
       "│ 6031 ┆ 5   ┆ 2045  ┆ 1           ┆ … ┆ [7123,       ┆ [31225,      ┆ [-20.370192, ┆ [true, true, │\n",
       "│      ┆     ┆       ┆             ┆   ┆ 10907, …     ┆ 24719, …     ┆ -20.601143,  ┆ … true]      │\n",
       "│      ┆     ┆       ┆             ┆   ┆ 86164]       ┆ 6031]        ┆ … -5.…       ┆              │\n",
       "└──────┴─────┴───────┴─────────────┴───┴──────────────┴──────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does it look like initially?\n",
    "pl.read_parquet(osp.join(single, 'inference_0.parquet')).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1bbdac-3b84-4202-acf0-bbbcb2e10cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:12:04.696839Z",
     "iopub.status.busy": "2025-08-13T18:12:04.696438Z",
     "iopub.status.idle": "2025-08-13T18:12:08.384603Z",
     "shell.execute_reply": "2025-08-13T18:12:08.384125Z",
     "shell.execute_reply.started": "2025-08-13T18:12:04.696823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single results shape: (129199, 7)\n"
     ]
    }
   ],
   "source": [
    "single_df = data_util.filter_process_results(\n",
    "    df=data_util.load_and_translate_results(\n",
    "        data_path=osp.dirname(single), results_folder=osp.basename(single)\n",
    "    ),\n",
    "    results_path=os.path.dirname(single),\n",
    ").unique()\n",
    "\n",
    "print(f\"Single results shape: {single_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060d6200-3367-43c9-9dfc-ccf5101f7e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T18:12:50.576214Z",
     "iopub.status.busy": "2025-08-13T18:12:50.575831Z",
     "iopub.status.idle": "2025-08-13T18:12:50.584623Z",
     "shell.execute_reply": "2025-08-13T18:12:50.584225Z",
     "shell.execute_reply.started": "2025-08-13T18:12:50.576199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>h_label</th><th>t_pred_label</th><th>h_name</th><th>r_label</th><th>t_pred_name</th><th>t_pred_score</th><th>edge_in_primekg</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>bool</td></tr></thead><tbody><tr><td>&quot;NCBI:7297&quot;</td><td>&quot;MONDO:1484&quot;</td><td>&quot;TYK2&quot;</td><td>&quot;associated with&quot;</td><td>&quot;paranoid schizophrenia&quot;</td><td>5.615732</td><td>true</td></tr><tr><td>&quot;NCBI:7297&quot;</td><td>&quot;MONDO:13276&quot;</td><td>&quot;TYK2&quot;</td><td>&quot;associated with&quot;</td><td>&quot;Reynolds syndrome&quot;</td><td>5.55585</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌───────────┬──────────────┬────────┬────────────┬─────────────────┬──────────────┬────────────────┐\n",
       "│ h_label   ┆ t_pred_label ┆ h_name ┆ r_label    ┆ t_pred_name     ┆ t_pred_score ┆ edge_in_primek │\n",
       "│ ---       ┆ ---          ┆ ---    ┆ ---        ┆ ---             ┆ ---          ┆ g              │\n",
       "│ str       ┆ str          ┆ str    ┆ str        ┆ str             ┆ f64          ┆ ---            │\n",
       "│           ┆              ┆        ┆            ┆                 ┆              ┆ bool           │\n",
       "╞═══════════╪══════════════╪════════╪════════════╪═════════════════╪══════════════╪════════════════╡\n",
       "│ NCBI:7297 ┆ MONDO:1484   ┆ TYK2   ┆ associated ┆ paranoid        ┆ 5.615732     ┆ true           │\n",
       "│           ┆              ┆        ┆ with       ┆ schizophrenia   ┆              ┆                │\n",
       "│ NCBI:7297 ┆ MONDO:13276  ┆ TYK2   ┆ associated ┆ Reynolds        ┆ 5.55585      ┆ true           │\n",
       "│           ┆              ┆        ┆ with       ┆ syndrome        ┆              ┆                │\n",
       "└───────────┴──────────────┴────────┴────────────┴─────────────────┴──────────────┴────────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_df.sort('t_pred_score', descending=True).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d8220-c48a-4a94-ae2f-eaa720f40aa6",
   "metadata": {},
   "source": [
    "## process test/valid batched data\n",
    "* Scores aren't kept in the test/valid setup - it would be ridiculous to keep every possible prediction when making 1.6 million queries (x 129,000)\n",
    "* If you want more than the top 100 results dumped, visit L193 in [run.py]('../../code/ULTRA/script/run.py'), modify the number, and re-run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fbec048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>h</th><th>r</th><th>t</th><th>h_pred</th><th>t_pred</th><th>h_rank</th><th>t_rank</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>4548</td><td>0</td><td>1420</td><td>[4115, 680, … 5985]</td><td>[2294, 10773, … 49463]</td><td>2</td><td>3</td></tr><tr><td>13859</td><td>0</td><td>1578</td><td>[8500, 5459, … 6112]</td><td>[5014, 29849, … 1897]</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌───────┬─────┬──────┬──────────────────────┬────────────────────────┬────────┬────────┐\n",
       "│ h     ┆ r   ┆ t    ┆ h_pred               ┆ t_pred                 ┆ h_rank ┆ t_rank │\n",
       "│ ---   ┆ --- ┆ ---  ┆ ---                  ┆ ---                    ┆ ---    ┆ ---    │\n",
       "│ i64   ┆ i64 ┆ i64  ┆ list[i64]            ┆ list[i64]              ┆ i64    ┆ i64    │\n",
       "╞═══════╪═════╪══════╪══════════════════════╪════════════════════════╪════════╪════════╡\n",
       "│ 4548  ┆ 0   ┆ 1420 ┆ [4115, 680, … 5985]  ┆ [2294, 10773, … 49463] ┆ 2      ┆ 3      │\n",
       "│ 13859 ┆ 0   ┆ 1578 ┆ [8500, 5459, … 6112] ┆ [5014, 29849, … 1897]  ┆ 1      ┆ 1      │\n",
       "└───────┴─────┴──────┴──────────────────────┴────────────────────────┴────────┴────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet(osp.join(batched,'valid_0.parquet')).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3a2e1",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-13T18:17:58.954Z",
     "iopub.execute_input": "2025-08-13T18:13:29.749297Z",
     "iopub.status.busy": "2025-08-13T18:13:29.748795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched results shape: (405004, 12)\n"
     ]
    }
   ],
   "source": [
    "# load in the batched predictions, 405,004 x 12 ...\n",
    "# missing 1/4 of the edge predictions... probably something to do with parallelization\n",
    "# in theory all items should of exported based on the machine rank.\n",
    "# reccommend just running the model above with 1 gpu (much slower) to mitigate this bug\n",
    "batched_df = data_util.load_and_translate_results(\n",
    "        data_path=osp.dirname(batched), results_folder=osp.basename(batched)\n",
    "    ).unique()\n",
    "\n",
    "print(f\"Batched results shape: {batched_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfca86a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>h</th><th>r</th><th>t</th><th>h_pred</th><th>t_pred</th><th>h_rank</th><th>t_rank</th><th>h_label</th><th>t_label</th><th>r_label</th><th>h_name</th><th>t_name</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>28601</td><td>1</td><td>27904</td><td>[29914, 26869, … 3346]</td><td>[5496, 4203, … 35376]</td><td>1</td><td>1</td><td>&quot;MONDO:18682&quot;</td><td>&quot;HPO:12745&quot;</td><td>&quot;phenotype present&quot;</td><td>&quot;congenital insensitivity to pa…</td><td>&quot;Short palpebral fissure&quot;</td></tr><tr><td>98</td><td>17</td><td>6240</td><td>[16995, 13542, … 6458]</td><td>[23653, 13262, … 132]</td><td>1</td><td>1</td><td>&quot;DrugBank:DB12466&quot;</td><td>&quot;NCBI:5005&quot;</td><td>&quot;carrier&quot;</td><td>&quot;Favipiravir&quot;</td><td>&quot;ORM2&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 12)\n",
       "┌───────┬─────┬───────┬───────────┬───┬───────────┬───────────┬──────────────────┬─────────────────┐\n",
       "│ h     ┆ r   ┆ t     ┆ h_pred    ┆ … ┆ t_label   ┆ r_label   ┆ h_name           ┆ t_name          │\n",
       "│ ---   ┆ --- ┆ ---   ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---              ┆ ---             │\n",
       "│ i64   ┆ i64 ┆ i64   ┆ list[i64] ┆   ┆ str       ┆ str       ┆ str              ┆ str             │\n",
       "╞═══════╪═════╪═══════╪═══════════╪═══╪═══════════╪═══════════╪══════════════════╪═════════════════╡\n",
       "│ 28601 ┆ 1   ┆ 27904 ┆ [29914,   ┆ … ┆ HPO:12745 ┆ phenotype ┆ congenital       ┆ Short palpebral │\n",
       "│       ┆     ┆       ┆ 26869, …  ┆   ┆           ┆ present   ┆ insensitivity to ┆ fissure         │\n",
       "│       ┆     ┆       ┆ 3346]     ┆   ┆           ┆           ┆ pa…              ┆                 │\n",
       "│ 98    ┆ 17  ┆ 6240  ┆ [16995,   ┆ … ┆ NCBI:5005 ┆ carrier   ┆ Favipiravir      ┆ ORM2            │\n",
       "│       ┆     ┆       ┆ 13542, …  ┆   ┆           ┆           ┆                  ┆                 │\n",
       "│       ┆     ┆       ┆ 6458]     ┆   ┆           ┆           ┆                  ┆                 │\n",
       "└───────┴─────┴───────┴───────────┴───┴───────────┴───────────┴──────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h_prediction and tail prediction aren't translated so we'll need to do so\n",
    "batched_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e182be93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>h_name</th><th>r_label</th><th>t_name</th><th>h_rank</th><th>t_rank</th><th>h_pred_name</th><th>t_pred_name</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>list[str]</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;congenital insensitivity to pa…</td><td>&quot;phenotype present&quot;</td><td>&quot;Short palpebral fissure&quot;</td><td>1</td><td>1</td><td>[&quot;autosomal dominant Robinow syndrome&quot;, &quot;C syndrome&quot;, … &quot;growth delay due to insulin-like growth factor I resistance&quot;]</td><td>[&quot;Global developmental delay&quot;, &quot;Intellectual disability&quot;, … &quot;Corneal scarring&quot;]</td></tr><tr><td>&quot;Favipiravir&quot;</td><td>&quot;carrier&quot;</td><td>&quot;ORM2&quot;</td><td>1</td><td>1</td><td>[&quot;collagen-containing extracellular matrix&quot;, &quot;positive regulation of tumor necrosis factor production&quot;, … &quot;negative regulation of apoptotic process&quot;]</td><td>[&quot;GDA&quot;, &quot;PNP&quot;, … &quot;small intestine&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌──────────────────┬───────────┬───────────┬────────┬────────┬──────────────────┬──────────────────┐\n",
       "│ h_name           ┆ r_label   ┆ t_name    ┆ h_rank ┆ t_rank ┆ h_pred_name      ┆ t_pred_name      │\n",
       "│ ---              ┆ ---       ┆ ---       ┆ ---    ┆ ---    ┆ ---              ┆ ---              │\n",
       "│ str              ┆ str       ┆ str       ┆ i64    ┆ i64    ┆ list[str]        ┆ list[str]        │\n",
       "╞══════════════════╪═══════════╪═══════════╪════════╪════════╪══════════════════╪══════════════════╡\n",
       "│ congenital       ┆ phenotype ┆ Short     ┆ 1      ┆ 1      ┆ [\"autosomal      ┆ [\"Global         │\n",
       "│ insensitivity to ┆ present   ┆ palpebral ┆        ┆        ┆ dominant Robinow ┆ developmental    │\n",
       "│ pa…              ┆           ┆ fissure   ┆        ┆        ┆ s…               ┆ delay\",…         │\n",
       "│ Favipiravir      ┆ carrier   ┆ ORM2      ┆ 1      ┆ 1      ┆ [\"collagen-conta ┆ [\"GDA\", \"PNP\", … │\n",
       "│                  ┆           ┆           ┆        ┆        ┆ ining extracel…  ┆ \"small intest…   │\n",
       "└──────────────────┴───────────┴───────────┴────────┴────────┴──────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary translation\n",
    "id2ent, id2rel, ent2name = data_util.load_id_dict(osp.dirname(batched))\n",
    "\n",
    "# translate the list by first replace number with id, then id with name/label\n",
    "batched_df = batched_df.with_columns(\n",
    "    pl.col(\"h_pred\")\n",
    "    .list.eval( # replace number with id\n",
    "        pl.element().map_elements(lambda x: id2ent.get(x, x), return_dtype=pl.String)\n",
    "    )\n",
    "    .list.eval( # replace id with name/label\n",
    "        pl.element().map_elements(lambda x: ent2name.get(x, x), return_dtype=pl.String)\n",
    "    )\n",
    "    .alias(\"h_pred_name\"),\n",
    "    pl.col('t_pred').list.eval(\n",
    "        pl.element().map_elements(lambda x: id2ent.get(x, x), return_dtype=pl.String)\n",
    "    ).list.eval(\n",
    "        pl.element().map_elements(lambda x: ent2name.get(x, x), return_dtype=pl.String)\n",
    "    ).alias('t_pred_name')\n",
    ")[['h_name','r_label','t_name','h_rank','t_rank','h_pred_name','t_pred_name']]\n",
    "\n",
    "batched_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ca7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultra",
   "language": "python",
   "name": "ultra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
